{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751750bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8628feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv, det\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "from torch import sigmoid, tanh\n",
    "from torch import Tensor, exp, log\n",
    "from torch.nn import Sequential\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.init import uniform_\n",
    "from torch.nn.functional import linear\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b29c7",
   "metadata": {},
   "source": [
    "paper: Neural Arithmetic Logic Units (https://arxiv.org/pdf/1808.00508.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7a1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for addition and subtraction\n",
    "class ASCell(nn.Module):\n",
    "    def __init__(self, in_shape, out_shape):\n",
    "        super().__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "\n",
    "        self.W_ = Parameter(Tensor(out_shape, in_shape))\n",
    "        self.M_ = Parameter(Tensor(out_shape, in_shape))\n",
    "\n",
    "        uniform_(self.W_, 0.0, 1.0), uniform_(self.M_, 0.0, 1.0)\n",
    "        self.register_parameter('bias', None)\n",
    "\n",
    "    # a = Wx\n",
    "    # W = tanh(W) * sigmoid(M)\n",
    "    # * is elementwise product\n",
    "    def forward(self, X):\n",
    "        #print('W:', self.W_.shape, 'X:', X.shape)\n",
    "        W = tanh(self.W_) * sigmoid(self.M_)\n",
    "\n",
    "        # linear: XW^T + b\n",
    "        return linear(X, W, self.bias)\n",
    "        #return torch.matmul(X, W.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8cca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for multiplication and division\n",
    "class MDCell(nn.Module):\n",
    "    def __init__(self, in_shape, out_shape):\n",
    "        super().__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "\n",
    "#         self.G = Parameter(Tensor(out_shape, in_shape))\n",
    "        self.nac = ASCell(in_shape, out_shape)\n",
    "\n",
    "#         uniform_(self.G, 0.0, 1.0)\n",
    "        # epsilon prevents log0\n",
    "        self.eps = 1e-5\n",
    "        self.register_parameter('bias', None)\n",
    "\n",
    "    # y = g * a + (1 - g) * m\n",
    "    # m = exp W(log(|x| + e)), g = sigmoid(Gx)\n",
    "    # * is elementwise product\n",
    "    # a is from nac\n",
    "    \n",
    "    # y = exp W(log(|X| + e))\n",
    "    # W = tanh(W) * sigmoid(M)\n",
    "    # * is elementalwise product\n",
    "    def forward(self, X):\n",
    "#         a = self.nac(X)\n",
    "#         g = sigmoid(linear(X, self.G, self.bias))\n",
    "\n",
    "#         ag = g * a\n",
    "        log_in = log(abs(X) + self.eps)\n",
    "        m = exp(self.nac(log_in))\n",
    "#         md = (1 - g) * m\n",
    "\n",
    "#         return ag + md\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9b9a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.MD1 = MDCell(in_shape=9, out_shape=6)\n",
    "        self.AS1 = ASCell(in_shape=6, out_shape=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.MD1(X)\n",
    "        X = self.AS1(X)\n",
    "        X = X.squeeze()\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73689b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9f45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b03ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271b694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cf4f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fcde23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NALU(input_shape=4, output_shape=1, n_layers=2, hidden_shape=2)\n",
    "model = Custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d424efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Custom(\n",
       "  (MD1): MDCell(\n",
       "    (nac): ASCell()\n",
       "  )\n",
       "  (AS1): ASCell()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eecc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TensorDataset(X_train, y_train)\n",
    "# dataset\n",
    "\n",
    "# b_size = 128\n",
    "# dataloader = DataLoader(dataset, batch_size=b_size, shuffle=True)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c55c7aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "cur_loss = 0.0\n",
    "epos = []\n",
    "los = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f8428c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\u001b[43mdataloader\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m tepoch:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tepoch):\n\u001b[1;32m      4\u001b[0m             tepoch\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    with tqdm(dataloader) as tepoch:\n",
    "        for batch_idx, samples in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            X_t, y_t = samples\n",
    "            \n",
    "            pred = model(X_t)\n",
    "            \n",
    "            pred = pred.squeeze()\n",
    "            cost = F.mse_loss(pred, y_t)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tepoch.set_postfix(loss=cost.item())\n",
    "            cur_loss = cost.item()\n",
    "            \n",
    "        epos.append(epoch + 1)\n",
    "        los.append(cur_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ad209",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ff713",
   "metadata": {},
   "source": [
    "initialization 에 따라 수렴 여부가 결정됨 -> 항상 수렴시킬 방법?\n",
    "\n",
    "-> initialization 할 때 exclude negative number\n",
    "\n",
    "-> 이래도 잘 안 됨. G 학습이 어려워서 그럴지도? G 를 학습시키지 말고 덧셈과 곱셈을 분리해버리면 어떨까?\n",
    "\n",
    "-> 훨씬 안정적임. G 가 문제였던 것 같음!!\n",
    "\n",
    "<!-- 음수가 포함되면 나누기 연산이 들어갈 확률이 높아져서 그런 것 같음 -->\n",
    "\n",
    "필요한 연산보다 더 많은 layer 를 만들면 학습이 되나?\n",
    "\n",
    "-> 되기는 하지만 타이트할 때보다 잘 되지는 않음\n",
    "\n",
    "그럼 이제 3 x 3 이랑 4 x 4 도전\n",
    "\n",
    "-> 3 x 3 은 성공 16023.6797\n",
    "\n",
    "-> 4 x 4 는 좀 어려운듯? 493209.6875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313aef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = 2\n",
    "# i = 4\n",
    "# o = 1\n",
    "# h = 2\n",
    "# for n in range(nn):\n",
    "#     f1 = h if n > 0 else i\n",
    "#     f2 = h if n < nn - 1 else o\n",
    "    \n",
    "#     print('({}, {})'.format(f1, f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epos, los, label='train')\n",
    "plt.title('model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "# plt.savefig('aaa.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(epos, los, label='train')\n",
    "# plt.title('model loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.legend()\n",
    "# plt.savefig('aaa.png')\n",
    "# plt.show()\n",
    "\n",
    "# torch.save(model, 'aaa.pt')\n",
    "\n",
    "# nn = 2\n",
    "# i = 4\n",
    "# o = 1\n",
    "# h = 2\n",
    "# for n in range(nn):\n",
    "#     f1 = h if n > 0 else i\n",
    "#     f2 = h if n < nn - 1 else o\n",
    "    \n",
    "#     print('({}, {})'.format(f1, f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840c0682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
